---
title: "AIRLINE ARRIVAL PROJECT"
output:
  html_notebook: default
  pdf_document: default
---

```{r}
# remove some junk
rm(list = ls())
```

# A. Exploratory Data Analysis (EDA)

## 1. import libraries and some options
```{r message=FALSE, warning=FALSE}
# import library
library(skimr) # for more detail summary
library(jsonlite) # for JSON purposes
library(jsonify) # for JSON purposes
library(glue) # general purposes
library(ggplot2) # for plotting
library(caret) # general purposes
library(bestNormalize) # for normalization
library(parallel) # for parallel computing
library(dplyr) # for general purposes
library(corrplot) # plot correlation
library(foreach) # for parallel computing
library(doParallel) # for parallel computing
library(mltools) # for machine learning purpose
library(data.table) # for create data.table
library(caTools) # for train/test split
library(Rtsne) # for tsne plotting
library(DMwR) # for smote implementation
library(ROSE)# for ROSE sampling
library(xgboost) # for xgboost model


# max print to 777 rows
options(max.print=777)

# define function to garbage collect
cl <- function(){
  rm()
  gc()
}
```

## 2. Prepare data
```{r}
# get directory of all file
foo <- system("ls /home/apolong72/ds/r/data/airline/", intern = T)
boo <- paste("/home/apolong72/ds/r/data/airline/", foo, sep = "")

# read all csv file
## use mclapply to trigger multi core progress
system.time(
  df <- mclapply(boo, read.csv, mc.cores = 6)
)

# concat to 1 df
df <- bind_rows(df)
```
### Quick look at data
```{r}
df
```

## 3.Remove some unused features (after manually analyse data)
```{r}
# remove some feature
remove.abc = c('DEP_DEL15', 'DEP_DELAY_GROUP', 'FLIGHTS', 'CANCELLED', 'DIVERTED','OP_CARRIER_AIRLINE_ID','ORIGIN_AIRPORT_ID','DEST_AIRPORT_ID','ARR_DELAY_NEW','DEP_DELAY_NEW')
```


```{r}
# 
df <- subset(df, select = -c(DEP_DEL15, DEP_DELAY_GROUP, FLIGHTS, CANCELLED, DIVERTED, OP_CARRIER_AIRLINE_ID, ORIGIN_AIRPORT_ID, DEST_AIRPORT_ID, ARR_DELAY_NEW, DEP_DELAY_NEW))

# remove index columns
df$X <- NULL

# create copy of df
## create sample for testing purpose
df2 <- df
df2_sample <- sample_n(df2, 100)
```


```{r}
# check all rows that have NA value
df2[!complete.cases(df2),]
```
### Around 150,000 rows have NA values, its not too much compare to more than 7,000,000 rows in total. So that we just remove all NA rows

```{r}
df3 <- df2[complete.cases(df2),]
```

## 4. Detail summary with `skim`
```{r}
system.time(
  skim_sum <- mclapply(df3, skim, mc.cores = 6)
)

skim_sum
```
#### We got some useful information. as we can see: `variable type` is messy, `Standard Deviation` is not clean, `quick hist plot` show some tail plot or head plot, and `mean` variable is not balance in specific range in each features.


## 5. Next we will figure out correlation of all features
```{r}
# pick only numeric columns for corr plot

foo <- unlist(lapply(df3,is.factor))
df3_numeric <- df3[!foo]

df3_numeric
```


```{r}
system.time(
cormat <- round(cor(df3_numeric), 2)
)
corr_df <- data.frame(cormat)

corr_df
```

### Plot Corr
```{r, fig.width = 15, fig.height=8}
# plot correlation 
## `tl.srt` is to rotate text
corrplot(cormat, type = "lower", tl.srt = 360, tl.col = "black")
```

### show all correlation > 0.8
```{r}
list_corr_above_0.8 <- list()
for (i in names(corr_df)) {
  a <- filter(corr_df[i], corr_df[i] > 0.8)
  list_corr_above_0.8[[i]] <- a
}

list_corr_above_0.8
```
#### - We can see that `CRS_ELAPSED_TIME` `ACTUAL_ELAPSED_TIME` `AIR_TIME` `DISTANCE` `DISTANCE_GROUP` have high corr each other, so we will just keep 1 of it
#### - `ACTUAL_ELAPSED_TIME` have highest corr with ARR_DELAY, so we will keep this and remove all 
#### - `DEP_TIME` and `WHEELS_OFF` have same highest corr, so we can choose, keep `DEP_TIME`
#### - We will remove DEP_DELAY too
#### - We still have `WHEELS_ON` high corr with `ARR_TIME` and `CRS_ARR_TIME`, remove `ARR_TIME`, `CRS_ARR_TIME`
```{r}
df3_numeric_reduce <- subset(df3_numeric, select = -c(CRS_ELAPSED_TIME, AIR_TIME, DISTANCE, DISTANCE_GROUP, CRS_DEP_TIME, WHEELS_OFF, DEP_DELAY, ARR_TIME, CRS_ARR_TIME))

df3_numeric_reduce
```


### Plot again
```{r, fig.width = 15, fig.height=8}
cormat_reduce <- round(cor(df3_numeric_reduce), 2)
corrplot(cormat_reduce, type = "lower", tl.srt = 360, tl.col = "black")
```
#### Ok, so we can see that no high correlation occur in out data now.
### We can now concat to original data
```{r}
df4 <- df3[,sapply(df3, is.factor)]
df4 <- cbind(df4, df3_numeric_reduce)

df4
```
## 6. Save file
```{r}
write.csv(df4, file = "/home/apolong72/ds/r/data/airline_2/all.csv", row.names = FALSE)
```

## ---------------RELOAD ALL (retrieve RAM purpose)---------------

### Since my computer dont have too much ram, I have to reload frequenly to have some space
```{r}
# remove some junk
rm(list = ls())
rm()
gc()
```

### Read data again
```{r}
df <- read.csv("/home/apolong72/ds/r/data/airline_2/all.csv")
# get copy of data
df_copy <- df

df
```

## 7. Write some useful functions
```{r}
# write some function to plot histogram and bar chart

## hist plot
plot.hist <- function (df, name) {
  ggplot( data=df, aes(x=df[, name])) + 
    geom_histogram(fill="skyblue", alpha=0.8, bins = 100) +
    labs(title="Histogram", subtitle=name, y="Count", x=name, caption="by Quan") +
    theme_minimal() +
    theme(text=element_text(size=14,  family="Arial", face = "bold"))
}

## box plot
plot.box <- function (df, name) {
  ggplot( data=df, aes(x=df[, name])) + 
    geom_boxplot(fill="skyblue", alpha=0.8,) +
    labs(title="Box Plot", subtitle=name, y="Count", x=name, caption="by Quan") +
    theme_minimal() +
    theme(text=element_text(size=14,  family="Arial", face = "bold"))
}

## bar plot
plot.bar <- function(df) {
  ggplot( data=df, aes(x=ind, y=values)) + 
    geom_bar(fill="skyblue",stat="identity") +
    labs(title="Bar Plot", subtitle="Most Frequence", y="Count", x="Name", caption="by Quan") +
    theme_minimal() +
    theme(text=element_text(size=14,  family="Arial", face = "bold"))
}


# create dist list 
dist.list <- function(df) {
  #
  list_temp <- list()
  name.df <- names(df)
  j <- 1
  #
  for (i in df) {
    list_temp[[name.df[j]]] <- summary(as.factor(i))
    j <- j + 1
  }
  
  return(list_temp)
}
```

## 8. Next we will get more insight of this data
### Create distinct values list for each feature
```{r}
dist_list <- dist.list(df)
dist_list_pretty <- mclapply(dist_list, function(x) stack(x), mc.cores = 6)

dist_list_pretty
```
### Use bar plot to show most 10 distinct value each features
```{r}
# plot top 10 most frequence values in each feature
plot_top_10_frequence <- mclapply(dist_list_pretty, function(x) {
  # head(order(x$values, decreasing = T), 10) : sort by values, pick top 10 frequence
  temp <- head(order(x$values, decreasing = T), 10)
  print(plot.bar(x[temp, ]))
}, mc.cores = 6)

plot_top_10_frequence
```
#### - We can see that some feature have very high `other` values, so its mean it have very much distinct value
#### - Not so much insight from this plot, but at least we will sure that no weird values at majority in any features


## 9. Next, we will convert `ARR_DELAY` to logical with meet code: 1 if later than 30 min, else 0
```{r}

temp <- ((df["ARR_DELAY"] > 30) * 1)
temp <- as.factor(temp)

# add new column LATE, remove ARR_DELAY
df$LATE <- temp
df$ARR_DELAY <- NULL

# we can see that `OP_CARRIER_FL_NUM` is similar to `OP_UNIQUE_CARRIER`, remove `OP_CARRIER_FL_NUM`
df$OP_CARRIER_FL_NUM <- NULL

df
```
## 10. We will then check outlier of all features

### Transfrom `MONTH`, `DAY_OF_MONTH`, `DAY_OF_WEEK` to factor type
```{r}
df <- transform(df, MONTH = as.factor(MONTH),
                      DAY_OF_MONTH = as.factor(DAY_OF_MONTH),
                      DAY_OF_WEEK = as.factor(DAY_OF_WEEK))
```


```{r}

## first, we need to have all distinct values of factor features:
temp <- lapply(df, is.factor)
df_factor <- df[,unlist(temp)]

# get factor features
dist_factor <- lapply(df_factor, function(x) stack(summary(x, maxsum=9999999)))
```

### Plot box plot 
```{r, fig.width = 12, fig.height=4}
# check box plot all dist_factor features
print(names(dist_factor))
for (i in dist_factor) {
  print(plot.box(i, "values"))
}
```
#### We see that some features have outliers

## 11. NORMAL DISTRIBUTION
### Get numeric features
```{r}
# get all numeric features
temp <- lapply(df,function(x) !is.factor(x))
df_numeric <- df[,unlist(temp)]

df_numeric
```
### Hist plot 
```{r, fig.width = 12, fig.height=4}
# hist plot all numeric features
for (i in names(df_numeric)){
  print(plot.hist(df_numeric, i))
}
```

### We will use yeo johnson algorithm to apply transform
```{r}
# apply transform_yeo for all features in df_numeric
transform_yeo <- mclapply(df_numeric, yeojohnson, mc.cores = 6)

# create a dataframe contain all transformed values for all features
system.time(
df_transform_yeo <- lapply(transform_yeo, function(i){data.frame("transform" = i$x.t)})
)

df_transform <- df_transform_yeo
df_transform
```

### Plot transformed features by histplot
```{r}
print(names(df_transform_yeo))
for (i in df_transform_yeo) print(plot.hist(i, name = "transform"))

```

#### We can see that features had normal distribution now, as well as well scaling 
## 12. Next, we will find outlier of these features
```{r}
# very useful trick to get outlier by using boxplot$out
outlier_list <- lapply(df_transform_yeo, function(x)boxplot(x, plot = F)$out)

```

### Update new values of numeric features to orig data
```{r}
df2 <- df
for (name in names(df_transform_yeo)){
  df2[,name] <- df_transform_yeo[[name]][,]
}

df2
```

### Remove outliers
```{r}
for (name in names(outlier_list)){
  df2 <- df2[which(!df2[,name] %in% outlier_list[[name]]),]
}

df2
```
#### More than 80,000 rows have been removed

### For future purposes, we will seperate target feature `LATE`
```{r}
# we split dataframe by target
df_late <- df2["LATE"]
df2$LATE <- NULL
```


## 13. ONE HOT ENCODING (we faced many problems, since my computer RAM don't have enough to apply One Hot. but you can try by your own computer)
```{r}
# option 1
dummy <- dummyVars(" ~ .", data=df2)
## Error: cannot allocate vector of size 42.5 Gb
## so that we didnt have enough RAM to store this variable ~
df3 <- data.frame(predict(dummy, newdata = df2)) 

# option 2
## Still error, problem occur because of RAM exceeded!
library(mltools)
library(data.table)
newdata <- one_hot(as.data.table(df2))
```


## 14. We have to just convert factor features to numerics distinct values
```{r}
# convert all factor to numeric
temp <- df2[,which(sapply(df2,is.factor))]
numeric_factor <- lapply(temp, as.numeric)

# apply transform_yeo for these feature
transform_yeo_factor<- mclapply(numeric_factor, yeojohnson, mc.cores = 6)

# make dataframe of these feature
system.time(
df_transform_yeo_factor <- lapply(transform_yeo_factor, function(i){data.frame("transform" = i$x.t)})
)
```

### Plot these features
```{r, fig.width = 12, fig.height=4}

print(names(df_transform_yeo_factor))
for (i in df_transform_yeo_factor) print(plot.hist(i, name = "transform"))

```
### Add these feature to orig data
```{r}
df3 <- df2
for (name in names(df_transform_yeo_factor)) {
  df3[,name] <- df_transform_yeo_factor[[name]]
}

# add target features again
df3$LATE <- df_late[,]

df3
```
## 15. Save file
```{r}
write.csv(df3, file = "/home/apolong72/ds/r/data/final.csv", row.names = FALSE)
```

# B. Apply Machine Learning

```{r}
# clean var
rm(list = ls())
rm()
gc()
```
## 1. Load file
```{r}
df <- read.csv(file = "/home/apolong72/ds/r/data/final.csv")
```

## 2. quick look at data
```{r}
df
```

### Convert type and Skim
```{r}
# convert target to factor type
df$LATE <- as.factor(df$LATE)

# skim
skim(df)
```
#### Data is better now, no `NA` , `sd` equal to 1, `hist` seem good enough.
## 3. Split data to train/test
```{r}
set.seed(123)
split <- sample.split(df$LATE, SplitRatio = 0.9)

train <- subset(df, split)
test <- subset(df, !split)

train
```
## 4. Check balance of target feature
```{r}
# check target feature in train set

print("unique value:")
table(train$LATE)
print("percent:")
table(train$LATE)[2]/table(train$LATE)[1] * 100

```

#### We can see that target feature is imbalance, so that we will approach difference from original
## Try some resampling algorithms:
## 5. Downsampling
```{r}
# down sample
set.seed(9560)
down_train <- downSample(x = train[, -ncol(train)], y = train$LATE)
# change target label to numeric
labels <- down_train$Class
y <- recode(labels, '0' = 0, "1" = 1)

table(down_train$Class)
```

#### So out data downsampled to around 1,500,000 rows
### We will then apply xgboost, for quick checking, we will just apply 20 round
```{r message=FALSE, warning=FALSE}
set.seed(42)
system.time(
  xgb <- xgboost(data = data.matrix(down_train[,-ncol(down_train)]), 
                 label = y,
                 eta = 0.6, # first learning rate
                 gamma = 0.1, # another learning rate
                 max_depth = 10, # max depth of each trees
                 nrounds = 20, # number of rounds to train
                 objective = "binary:logistic", # binary target
                 colsample_bytree = 0.6, # use 60% to resampling each rows
                 # verbose = 1,
                 nthread = 5, # control number of core to running parallel
  )
)

# save model
xgb.save(xgb, "/home/apolong72/ds/r/data/airline_2/model/xgb.model")
```

### Predict in test set
```{r}
xgb_pred <- predict(xgb, data.matrix(test[,-length(test)]))

head(xgb_pred)
```

### Plot ROC
```{r}
roc_auc <- roc.curve(test$LATE, xgb_pred, plotit = TRUE)
```
#### In general, we will choose threshold have farest distant, we can see that around False positive ~= 0.23 have farest distant
```{r}
# lets check false positive rate 
roc_auc$false.positive.rate[roc_auc$false.positive.rate < 0.3]
```


```{r}
# we will choose `0.2323690109`

# we cannot use logical `==` because `roc_auc$false.positive.rate` auto round some digit, hard to catch up with what, so we will use logical `<=`
get_num <- which(roc_auc$false.positive.rate <= 0.232369011)[1]
```


```{r}
# check values of false positive
roc_auc$false.positive.rate[get_num]

# check values of true positive
roc_auc$true.positive.rate[get_num]

# get threshold
th <- roc_auc$thresholds[get_num]
th
```

### Ok we had the best threshold until now , we will use it for calculate the accuracy of test set
```{r}
# get predicted binary
pred_label <- (xgb_pred > th) * 1
distinct_pred <- table(test$LATE == pred_label)
distinct_pred

# calculate accuracy
acc <- 100 - (distinct_pred[1] / distinct_pred[2] * 100)
print(paste("accuracy is:", as.character(unname(acc)),"%", sep = " "))
```

## 6. Upsampling
### Similar to downsampling
```{r}
# down sample
set.seed(9560)
up_train <- upSample(x = train[, -ncol(train)], y = train$LATE)

# change target label to numeric
labels <- up_train$Class
y <- recode(labels, '0' = 0, "1" = 1)

table(up_train$Class)
```

#### So out data downsampled to around 11,500,000 rows
#### You can now apply same method of up sample algorithms, I will not run it, because it will take so much time.

## 7. ROSE algorithms and GridsearchCV
### We will down sampling to 50,000 samples to apply Gridsearch CV
```{r}
# get sample data ( around 50,000)
split <- sample.split(train$LATE, SplitRatio = 0.01)
sample_df <- subset(train, split)

# split to train/test
split2 <- sample.split(sample_df$LATE, SplitRatio = 0.7)
s_train <- subset(sample_df, split2)
s_test <- subset(sample_df, !split2)

s_train
```


### We will apply ROSE algorithms to resampling data
#### (ROSE and SMOTE algorithms is a very popular resampling algorithms, and they usually outperform original algorithms like Upsampling..) 
```{r}
# ROSE 

# down sample
set.seed(9560)
rose_s_train <- ROSE(LATE ~., data=s_train)$data

# change target label to numeric
labels <- rose_s_train$LATE
y <- recode(labels, "0" = 0, "1" = 1)

table(rose_s_train$LATE)
```

#### As you can see, ROSE keep rows remain, but balance target binary.
### Next, we will set parameter for grid search
```{r}
searchGridSubCol <- expand.grid(subsample = c(0.5, 1), 
                                colsample_bytree = c(0.5, 0.6), # resampling each rows
                                max_depth = 10, # max depth of each trees
                                eta = c(0.2, 0.3, 0.5), # first learning rate
                                lambda = c(0.5, 1),
                                # min_child_weight = c(1,3),
                                gamma = c(0.1, 0.5) # another learning rate
                                
)
```

### Apply grid search
```{r message=FALSE, warning=FALSE}
system.time(
rmseErrorsHyperparameters <- apply(searchGridSubCol, 1, function(parameterList){

  #Extract Parameters to test
  currentSubsampleRate <- parameterList[["subsample"]]
  currentColsampleRate <- parameterList[["colsample_bytree"]]
  currentDepth <- parameterList[["max_depth"]]
  currentEta <- parameterList[["eta"]]
  # currentMinChild <- parameterList[["min_child_weight"]]
  currentLambda <- parameterList[["lambda"]]
  currentGamma <- parameterList[["gamma"]]
  
  # Apply
  xgboostModelCV <- xgb.cv(data = data.matrix(rose_s_train[,-ncol(rose_s_train)]), 
                           label = y,
                           nrounds = 50, 
                           nfold = 5, 
                           showsd = TRUE, 
                           metrics = "rmse", 
                           verbose = FALSE, 
                           print_every_n = 10,
                           booster = "gbtree",
                           early_stopping_rounds = 10,
                           "eval_metric" = "rmse",
                           "objective" = "binary:logistic",
                           "max.depth" = currentDepth, 
                           "eta" = currentEta,                               
                           "subsample" = currentSubsampleRate,
                           "colsample_bytree" = currentColsampleRate,
                           # "min_child_weight" = currentMinChild,
                           "gamma" = currentGamma,
                           "lambda" = currentLambda
                           )
  
  xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
  
  # get rmse
  rmse <- tail(xvalidationScores$test_rmse_mean, 1)
  trmse <- tail(xvalidationScores$train_rmse_mean,1)
  
  output <- return(c(rmse, trmse, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentGamma, currentLambda))}
  
  )
)
```
### Create dataframe for results
```{r}
output <- as.data.frame(t(rmseErrorsHyperparameters))
varnames <- c("TestRMSE", "TrainRMSE", "SubSampRate", "ColSampRate", "Depth", "eta", "Gamma", "Lambda")
names(output) <- varnames

# sort the best rmse
output[order(output$TestRMSE),]
```

### We pick the best params ( lowest RMSE test)
```{r}
best_param <- output[order(output$TestRMSE),][1,-c(1,2)]
best_param
```

### Ok now, we will use ROSE algorithms apply to original data, and use best params to predict target

## 8. ROSE algorithm
```{r}
# ROSE 

# down sample
set.seed(9560)
rose_train <- ROSE(LATE ~., data=train)$data

# change target label to numeric
labels <- rose_train$LATE
y <- recode(labels, "0" = 0, "1" = 1)

table(rose_train$LATE)

```


### We will apply xgboost, for quick checking, we will just apply 20 round
```{r message=FALSE, warning=FALSE}
set.seed(42)
system.time(
  xgb_rose <- xgboost(data = data.matrix(rose_train[,-ncol(rose_train)]), 
                 label = y,
                 eta = best_param$eta, # first learning rate
                 gamma = best_param$Gamma, # another learning rate
                 max_depth = best_param$Depth, # max depth of each trees
                 nrounds = 20, # number of rounds to train
                 objective = "binary:logistic", # binary target
                 colsample_bytree = best_param$ColSampRate, # resampling each rows
                 lambda = best_param$Lambda,
                 subsample = best_param$SubSampRate,
                 # verbose = 1,
                 nthread = 5, # control number of core to running parallel
  )
)

# save model
xgb.save(xgb_rose, "/home/apolong72/ds/r/data/airline_2/model/xgb_rose.model")
```

### Predict in test set
```{r}
xgb_pred_rose <- predict(xgb_rose, data.matrix(test[,-length(test)]))

head(xgb_pred_rose)
```

### Plot ROC
```{r}
roc_auc <- roc.curve(test$LATE, xgb_pred_rose, plotit = TRUE)
```
#### In general, we will choose threshold have farest distant, we can see that around False positive ~= 0.3 have farest distant
```{r}
# lets check false positive rate 
roc_auc$false.positive.rate[roc_auc$false.positive.rate <= 0.3]
```


```{r}
# we will choose `0.2939281109`

# we cannot use logical `==` because `roc_auc$false.positive.rate` auto round some digit, hard to catch up with what, so we will use logical `<=`
get_num <- which(roc_auc$false.positive.rate <= 0.3)[1]
```


```{r}
# check values of false positive
roc_auc$false.positive.rate[get_num]

# check values of true positive
roc_auc$true.positive.rate[get_num]

# get threshold
th <- roc_auc$thresholds[get_num]
th
```

### We had the best threshold until now , we will use it for calculate the accuracy of test set
```{r}
# get predicted binary
pred_label <- (xgb_pred > th) * 1
distinct_pred <- table(test$LATE == pred_label)
distinct_pred

# calculate accuracy
acc <- 100 - (distinct_pred[1] / distinct_pred[2] * 100)
print(paste("accuracy is:", as.character(unname(acc)),"%", sep = " "))
```
#### We can see that prediction is not too good, its because we set parameter `route` too small, and `learning rate` is quite small too.
### We will then plot a chart to prove:

```{r}
ggplot(data=xgb_rose$evaluation_log, aes(x=iter, y=train_logloss)) +
  geom_line()
```
#### Easy to see that loss is potentially reduce more, so in this case, we just need to incease number of rounds, so that our model will be better

# END

